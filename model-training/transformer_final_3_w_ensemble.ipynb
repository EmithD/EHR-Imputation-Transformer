{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativePositionEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Learnable relative position encoding for features in the transformer model.\n",
    "    This allows the model to understand relationships between features based on their positions.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_seq_len, d_model):\n",
    "        super().__init__()\n",
    "        # Create a learnable embedding for relative positions\n",
    "        self.rel_pos_embedding = nn.Parameter(torch.randn(2 * max_seq_len - 1, d_model))\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Apply relative positional encodings to the input.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor [batch_size, seq_len, d_model]\n",
    "            \n",
    "        Returns:\n",
    "            Tensor with relative positional information.\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        # Create position indices matrix\n",
    "        pos_indices = torch.arange(seq_len, device=x.device)\n",
    "        # Calculate relative positions: for each position i, calculate its relative distance to each position j\n",
    "        rel_pos_indices = pos_indices.unsqueeze(1) - pos_indices.unsqueeze(0) + self.max_seq_len - 1\n",
    "        \n",
    "        # Get embeddings for each relative position\n",
    "        rel_pos_encoded = self.rel_pos_embedding[rel_pos_indices]\n",
    "        \n",
    "        return rel_pos_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWithRelPos(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head attention with relative positional encoding.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1, max_seq_len=1000):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        \n",
    "        # Linear projections for Q, K, V\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        self.k_proj = nn.Linear(d_model, d_model)\n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Relative position encoding\n",
    "        self.rel_pos_encoding = RelativePositionEncoding(max_seq_len, d_model)\n",
    "        \n",
    "        # Separate linear projection for relative position attention\n",
    "        self.rel_pos_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Scaling factor for dot product attention\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, key_padding_mask=None, need_weights=False):\n",
    "        \"\"\"\n",
    "        Forward pass with relative positional encoding.\n",
    "        \n",
    "        Args:\n",
    "            query, key, value: Input tensors [batch_size, seq_len, d_model]\n",
    "            key_padding_mask: Mask for padded values [batch_size, seq_len]\n",
    "            need_weights: Whether to return attention weights\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor and optionally attention weights\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "        seq_len = query.size(1)\n",
    "        \n",
    "        # Linear projections and reshape for multi-head attention\n",
    "        q = self.q_proj(query).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.k_proj(key).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_proj(value).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Compute content-based attention scores\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale  # [batch, heads, seq_len, seq_len]\n",
    "        \n",
    "        # Create relative position bias\n",
    "        # We'll use a simpler approach that's more efficient and avoids shape mismatches\n",
    "        rel_bias = torch.zeros((seq_len, seq_len), device=query.device)\n",
    "        positions = torch.arange(seq_len, device=query.device)\n",
    "        relative_positions = positions.unsqueeze(1) - positions.unsqueeze(0)\n",
    "        \n",
    "        # Convert to a simple positional bias (closer = higher attention)\n",
    "        rel_bias = -torch.abs(relative_positions) * 0.1\n",
    "        \n",
    "        # Add the positional bias to the attention scores\n",
    "        # We add the same bias for all heads and batches\n",
    "        attn_scores = attn_scores + rel_bias.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if key_padding_mask is not None:\n",
    "            # Convert mask to attention mask (True = ignore)\n",
    "            attn_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "            attn_scores = attn_scores.masked_fill(attn_mask, float('-inf'))\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Apply attention weights to values\n",
    "        output = torch.matmul(attn_weights, v)  # [batch, heads, seq_len, head_dim]\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        \n",
    "        # Final linear projection\n",
    "        output = self.out_proj(output)\n",
    "        \n",
    "        if need_weights:\n",
    "            return output, attn_weights\n",
    "        else:\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativePositionTransformerLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer encoder layer with relative positional encoding.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, \n",
    "                 activation=\"gelu\", max_seq_len=1000, norm_first=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multi-head attention with relative position encoding\n",
    "        self.self_attn = MultiHeadAttentionWithRelPos(\n",
    "            d_model, nhead, dropout=dropout, max_seq_len=max_seq_len\n",
    "        )\n",
    "        \n",
    "        # Feedforward network\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        \n",
    "        # Normalization and dropout\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Activation function\n",
    "        self.activation = getattr(nn.functional, activation)\n",
    "        self.norm_first = norm_first\n",
    "        \n",
    "    def forward(self, src, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the transformer layer.\n",
    "        \n",
    "        Args:\n",
    "            src: Input tensor [batch_size, seq_len, d_model]\n",
    "            src_key_padding_mask: Mask for padded values [batch_size, seq_len]\n",
    "            \n",
    "        Returns:\n",
    "            Processed tensor\n",
    "        \"\"\"\n",
    "        # Pre-norm architecture\n",
    "        if self.norm_first:\n",
    "            # Multi-head attention block with pre-normalization\n",
    "            src2 = self.norm1(src)\n",
    "            src2 = self.self_attn(src2, src2, src2, key_padding_mask=src_key_padding_mask)\n",
    "            src = src + self.dropout1(src2)\n",
    "            \n",
    "            # Feedforward block with pre-normalization\n",
    "            src2 = self.norm2(src)\n",
    "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))\n",
    "            src = src + self.dropout2(src2)\n",
    "        else:\n",
    "            # Multi-head attention block with post-normalization\n",
    "            src2 = self.self_attn(src, src, src, key_padding_mask=src_key_padding_mask)\n",
    "            src = self.norm1(src + self.dropout1(src2))\n",
    "            \n",
    "            # Feedforward block with post-normalization\n",
    "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "            src = self.norm2(src + self.dropout2(src2))\n",
    "            \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativePositionTransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer encoder with relative positional encoding.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder_layer, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([encoder_layer for _ in range(num_layers)])\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def forward(self, src, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the transformer encoder.\n",
    "        \n",
    "        Args:\n",
    "            src: Input tensor [batch_size, seq_len, d_model]\n",
    "            mask: Mask for padded values [batch_size, seq_len]\n",
    "            \n",
    "        Returns:\n",
    "            Encoded tensor\n",
    "        \"\"\"\n",
    "        output = src\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_key_padding_mask=mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularTransformerWithRelPos(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer model for tabular data with relative positional encoding.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_features, \n",
    "                 d_model=128, \n",
    "                 nhead=8, \n",
    "                 num_layers=3, \n",
    "                 dim_feedforward=512, \n",
    "                 dropout=0.1, \n",
    "                 activation='gelu',\n",
    "                 max_seq_len=1000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        # Enhanced feature value embedding\n",
    "        self.value_embedding = nn.Sequential(\n",
    "            nn.Linear(1, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout * 0.5),  # Lower initial dropout\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        # Feature interaction module\n",
    "        self.feature_interaction = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        \n",
    "        # Column embedding (learnable)\n",
    "        self.column_embedding = nn.Embedding(num_features, d_model)\n",
    "        \n",
    "        # Layer normalization before transformer\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Create encoder layer with relative position encoding\n",
    "        encoder_layer = RelativePositionTransformerLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "            max_seq_len=max_seq_len,\n",
    "            norm_first=True\n",
    "        )\n",
    "        \n",
    "        # Create transformer encoder\n",
    "        self.transformer_encoder = RelativePositionTransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # Enhanced output projection with skip connection\n",
    "        self.output_projection = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights using Xavier initialization\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                \n",
    "    def _generate_attention_mask(self, mask):\n",
    "        \"\"\"Generate attention mask for transformer\"\"\"\n",
    "        if mask is None:\n",
    "            return None\n",
    "        # Convert binary mask to attention mask (1 = don't attend, 0 = attend)\n",
    "        attn_mask = mask.bool()\n",
    "        return attn_mask\n",
    "                \n",
    "    def forward(self, x, column_indices, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the transformer model with relative position encoding.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor [batch_size, num_features]\n",
    "            column_indices: Tensor of column indices [num_features]\n",
    "            mask: Optional mask for missing values [batch_size, num_features]\n",
    "            \n",
    "        Returns:\n",
    "            Tensor of predicted values [batch_size, num_features]\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Reshape to [batch_size, num_features, 1] for embedding\n",
    "        x = x.unsqueeze(-1)\n",
    "        \n",
    "        # Embed feature values\n",
    "        x_embedded = self.value_embedding(x)\n",
    "        \n",
    "        # Add column embeddings\n",
    "        col_embed = self.column_embedding(column_indices).unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        x_embedded = x_embedded + col_embed\n",
    "        \n",
    "        # Apply feature interaction\n",
    "        x_interacted = self.feature_interaction(x_embedded)\n",
    "        x_embedded = x_embedded + x_interacted  # Residual connection\n",
    "        \n",
    "        # Apply layer normalization\n",
    "        x_embedded = self.norm(x_embedded)\n",
    "        \n",
    "        # Generate attention mask if needed\n",
    "        attn_mask = self._generate_attention_mask(mask) if mask is not None else None\n",
    "        \n",
    "        # Pass through transformer encoder with relative position encoding\n",
    "        x_encoded = self.transformer_encoder(x_embedded, attn_mask)\n",
    "        \n",
    "        # Project to output\n",
    "        output = self.output_projection(x_encoded).squeeze(-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Ensemble of transformer models for improved prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, config, num_models=3):\n",
    "        super().__init__()\n",
    "        self.num_models = num_models\n",
    "        \n",
    "        # Create multiple base models\n",
    "        self.models = nn.ModuleList([\n",
    "            TabularTransformerWithRelPos(\n",
    "                num_features=num_features,\n",
    "                d_model=config[\"d_model\"],\n",
    "                nhead=config[\"num_heads\"],\n",
    "                num_layers=config[\"num_layers\"],\n",
    "                dim_feedforward=config[\"dim_feedforward\"],\n",
    "                dropout=config[\"dropout\"],\n",
    "                activation=config[\"activation\"],\n",
    "                max_seq_len=max(2 * num_features, 100)\n",
    "            ) for _ in range(num_models)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, column_indices, mask=None):\n",
    "        # Get predictions from all models\n",
    "        all_preds = []\n",
    "        for model in self.models:\n",
    "            preds = model(x, column_indices, mask)\n",
    "            all_preds.append(preds.unsqueeze(0))\n",
    "        \n",
    "        # Stack and average predictions\n",
    "        all_preds = torch.cat(all_preds, dim=0)\n",
    "        avg_preds = torch.mean(all_preds, dim=0)\n",
    "        \n",
    "        return avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_missing_mask(data, missing_fraction=0.2, mechanism=\"MCAR\"):\n",
    "    \"\"\"\n",
    "    Create a mask for missing values using different mechanisms.\n",
    "    \n",
    "    Args:\n",
    "        data (torch.Tensor): Input data tensor\n",
    "        missing_fraction (float): Fraction of values to mask\n",
    "        mechanism (str): One of \"MCAR\", \"MAR\", or \"MNAR\"\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Binary mask (1 = missing, 0 = present)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # MCAR implementation - completely random\n",
    "        if mechanism == \"MCAR\":\n",
    "            mask = torch.rand(data.shape, device=data.device) < missing_fraction\n",
    "            return mask.int()\n",
    "        \n",
    "        # Simulated MAR (missing at random) implementation\n",
    "        # In MAR, missingness depends on observed values but not on missing values\n",
    "        elif mechanism == \"MAR\":\n",
    "            # Create a base random mask\n",
    "            mask = torch.zeros(data.shape, device=data.device, dtype=torch.int)\n",
    "            \n",
    "            # Number of features\n",
    "            num_features = data.shape[1]\n",
    "            \n",
    "            # For each column, make missingness depend on values in other columns\n",
    "            for col_idx in range(num_features):\n",
    "                # Choose a different column as predictor (wrapping around if needed)\n",
    "                predictor_col = (col_idx + 1) % num_features\n",
    "                \n",
    "                # Get predictor values\n",
    "                predictor_values = data[:, predictor_col]\n",
    "                \n",
    "                # Normalize predictor values to [0, 1] range\n",
    "                if predictor_values.max() > predictor_values.min():\n",
    "                    normalized_values = (predictor_values - predictor_values.min()) / (predictor_values.max() - predictor_values.min())\n",
    "                else:\n",
    "                    normalized_values = torch.zeros_like(predictor_values)\n",
    "                \n",
    "                # Higher predictor values = higher chance of missingness\n",
    "                # Add randomness to avoid making it purely deterministic\n",
    "                prob = normalized_values * 0.5 + torch.rand(data.shape[0], device=data.device) * 0.5\n",
    "                mask[:, col_idx] = (prob > (1 - missing_fraction)).int()\n",
    "            \n",
    "            return mask\n",
    "        \n",
    "        # Simulated MNAR (missing not at random) implementation\n",
    "        # In MNAR, missingness depends on the missing values themselves\n",
    "        elif mechanism == \"MNAR\":\n",
    "            # Create a base random mask\n",
    "            mask = torch.zeros(data.shape, device=data.device, dtype=torch.int)\n",
    "            \n",
    "            # For each column, make missingness depend on its own values\n",
    "            for col_idx in range(data.shape[1]):\n",
    "                # Get column values\n",
    "                col_values = data[:, col_idx]\n",
    "                \n",
    "                # Normalize values to [0, 1] range\n",
    "                if col_values.max() > col_values.min():\n",
    "                    normalized_values = (col_values - col_values.min()) / (col_values.max() - col_values.min())\n",
    "                else:\n",
    "                    normalized_values = torch.zeros_like(col_values)\n",
    "                \n",
    "                # For MNAR, higher values have higher probability of being missing\n",
    "                # Add randomness to avoid making it purely deterministic\n",
    "                prob = normalized_values * 0.7 + torch.rand(data.shape[0], device=data.device) * 0.3\n",
    "                mask[:, col_idx] = (prob > (1 - missing_fraction)).int()\n",
    "            \n",
    "            return mask\n",
    "        \n",
    "        # Default to MCAR if unknown mechanism\n",
    "        else:\n",
    "            print(f\"Unknown missing data mechanism: {mechanism}. Defaulting to MCAR.\")\n",
    "            return create_missing_mask(data, missing_fraction, \"MCAR\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating {mechanism} mask: {e}\")\n",
    "        # Fall back to MCAR if there's an error\n",
    "        return create_missing_mask(data, missing_fraction, \"MCAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(data_path, test_size=0.2, val_size=0.1, random_state=SEED):\n",
    "    \"\"\"\n",
    "    Load and prepare data for model training.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to the CSV file\n",
    "        test_size (float): Proportion of data to use for testing\n",
    "        val_size (float): Proportion of training data to use for validation\n",
    "        random_state (int): Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Preprocessed train, validation, test tensors, scaler, and column indices\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {data_path}\")\n",
    "    df = pd.read_csv(data_path, index_col=None)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_count = df.isna().sum().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"Warning: Dataset contains {missing_count} missing values. These will be handled in preprocessing.\")\n",
    "        # Simple imputation for missing values\n",
    "        df = df.fillna(df.mean())\n",
    "    \n",
    "    # Convert to numpy for preprocessing\n",
    "    data = df.to_numpy()\n",
    "    \n",
    "    # Split data into train and test\n",
    "    train_val_data, test_data = train_test_split(\n",
    "        data, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Split train_val into train and validation\n",
    "    val_ratio = val_size / (1 - test_size)\n",
    "    train_data, val_data = train_test_split(\n",
    "        train_val_data,\n",
    "        test_size=val_ratio,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Normalize data\n",
    "    scaler = StandardScaler()\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    val_data_scaled = scaler.transform(val_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    train_tensor = torch.tensor(train_data_scaled, dtype=torch.float32).to(device)\n",
    "    val_tensor = torch.tensor(val_data_scaled, dtype=torch.float32).to(device)\n",
    "    test_tensor = torch.tensor(test_data_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Create column indices\n",
    "    column_indices = torch.arange(train_tensor.shape[1]).to(device)\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Number of training samples: {train_tensor.shape[0]}\")\n",
    "    print(f\"Number of validation samples: {val_tensor.shape[0]}\")\n",
    "    print(f\"Number of test samples: {test_tensor.shape[0]}\")\n",
    "    print(f\"Number of features: {train_tensor.shape[1]}\")\n",
    "    \n",
    "    return train_tensor, val_tensor, test_tensor, scaler, column_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(predictions, ground_truth, mask, mechanism=None):\n",
    "    \"\"\"\n",
    "    Compute mean squared error loss on masked positions with optional mechanism-specific weighting.\n",
    "    \n",
    "    Args:\n",
    "        predictions (torch.Tensor): Predicted values\n",
    "        ground_truth (torch.Tensor): True values\n",
    "        mask (torch.Tensor): Binary mask (1 = missing, 0 = present)\n",
    "        mechanism (str): Missing data mechanism (MCAR, MAR, MNAR)\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Mean squared error loss\n",
    "    \"\"\"\n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    loss = mse_loss(predictions, ground_truth)\n",
    "    \n",
    "    # Apply mechanism-specific weighting\n",
    "    if mechanism == \"MNAR\":\n",
    "        # Higher weight for MNAR samples to focus training\n",
    "        weight = 1.5\n",
    "    else:\n",
    "        weight = 1.0\n",
    "    \n",
    "    # Normalize by number of masked positions\n",
    "    masked_loss = (loss * mask * weight).sum() / ((mask * weight).sum() + 1e-8)\n",
    "    return masked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(predictions, ground_truth, mask):\n",
    "    \"\"\"\n",
    "    Compute Root Mean Squared Error on masked positions.\n",
    "    \n",
    "    Args:\n",
    "        predictions (torch.Tensor): Predicted values\n",
    "        ground_truth (torch.Tensor): True values\n",
    "        mask (torch.Tensor): Binary mask (1 = missing, 0 = present)\n",
    "        \n",
    "    Returns:\n",
    "        float: RMSE value\n",
    "    \"\"\"\n",
    "    masked_preds = predictions[mask == 1]\n",
    "    masked_truth = ground_truth[mask == 1]\n",
    "    \n",
    "    if len(masked_preds) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    mse = torch.mean((masked_preds - masked_truth) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nrmse(predictions, ground_truth, mask):\n",
    "    \"\"\"\n",
    "    Compute Normalized Root Mean Squared Error on masked positions.\n",
    "    \n",
    "    Args:\n",
    "        predictions (torch.Tensor): Predicted values\n",
    "        ground_truth (torch.Tensor): True values\n",
    "        mask (torch.Tensor): Binary mask (1 = missing, 0 = present)\n",
    "        \n",
    "    Returns:\n",
    "        float: NRMSE value\n",
    "    \"\"\"\n",
    "    masked_preds = predictions[mask == 1]\n",
    "    masked_truth = ground_truth[mask == 1]\n",
    "    \n",
    "    if len(masked_preds) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    mse = torch.mean((masked_preds - masked_truth) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    \n",
    "    data_range = ground_truth.max() - ground_truth.min()\n",
    "    nrmse = rmse / data_range\n",
    "    return nrmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, missing_fraction, mechanisms=None, scheduler=None, focus_mnar=False):\n",
    "    \"\"\"\n",
    "    Train for one epoch with mixup data augmentation and gradient clipping.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Model to train\n",
    "        dataloader (DataLoader): Training data loader\n",
    "        optimizer (Optimizer): Optimizer\n",
    "        missing_fraction (float): Fraction of values to mask\n",
    "        mechanisms (list): List of missing data mechanisms to use\n",
    "        scheduler (LRScheduler, optional): Learning rate scheduler\n",
    "        focus_mnar (bool): Whether to focus training on MNAR mechanism\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with training metrics\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Mixup probability\n",
    "    mixup_prob = 0.3\n",
    "    \n",
    "    if mechanisms is None:\n",
    "        mechanisms = [\"MCAR\"]\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        x = batch[0].to(device)\n",
    "        \n",
    "        # Mechanism selection with optional MNAR focus\n",
    "        if focus_mnar and random.random() < 0.7:  # 70% chance to use MNAR when focusing on it\n",
    "            mechanism = \"MNAR\"\n",
    "        else:\n",
    "            mechanism = random.choice(mechanisms)\n",
    "        \n",
    "        # Create a mask for missing values\n",
    "        mask = create_missing_mask(x, missing_fraction, mechanism)\n",
    "        \n",
    "        # Create input with missing values set to 0\n",
    "        x_masked = x.clone()\n",
    "        x_masked[mask == 1] = 0\n",
    "        \n",
    "        # Apply mixup with probability\n",
    "        if random.random() < mixup_prob:\n",
    "            # Create shuffled indices\n",
    "            indices = torch.randperm(x.size(0), device=device)\n",
    "            \n",
    "            # Mix up samples with lambda drawn from beta distribution\n",
    "            lam = np.random.beta(0.2, 0.2)\n",
    "            \n",
    "            # Mix the data\n",
    "            mixed_x = lam * x_masked + (1 - lam) * x_masked[indices]\n",
    "            mixed_mask = mask | mask[indices]  # Union of masks\n",
    "            \n",
    "            # Forward pass with mixed data\n",
    "            optimizer.zero_grad()\n",
    "            column_indices = torch.arange(x.shape[1], device=device)\n",
    "            predictions = model(mixed_x, column_indices, mixed_mask)\n",
    "            \n",
    "            # Compute mixed loss\n",
    "            loss = lam * compute_loss(predictions, x, mask, mechanism) + \\\n",
    "                   (1 - lam) * compute_loss(predictions, x[indices], mask[indices], mechanism)\n",
    "        else:\n",
    "            # Standard forward pass\n",
    "            optimizer.zero_grad()\n",
    "            column_indices = torch.arange(x.shape[1], device=device)\n",
    "            predictions = model(x_masked, column_indices, mask)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = compute_loss(predictions, x, mask, mechanism)\n",
    "            \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Add gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return {\"loss\": avg_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, missing_fraction, mechanisms=None):\n",
    "    \"\"\"\n",
    "    Validate the model on all mechanisms.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Model to validate\n",
    "        dataloader (DataLoader): Validation data loader\n",
    "        missing_fraction (float): Fraction of values to mask\n",
    "        mechanisms (list): List of missing data mechanisms to use\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with validation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_rmse = 0\n",
    "    total_nrmse = 0\n",
    "    \n",
    "    if mechanisms is None:\n",
    "        mechanisms = [\"MCAR\"]\n",
    "    \n",
    "    mechanism_metrics = {m: {\"loss\": 0, \"rmse\": 0, \"nrmse\": 0, \"count\": 0} for m in mechanisms}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x = batch[0].to(device)\n",
    "            \n",
    "            for mechanism in mechanisms:\n",
    "                # Create a mask for missing values\n",
    "                mask = create_missing_mask(x, missing_fraction, mechanism)\n",
    "                \n",
    "                # Create input with missing values set to 0\n",
    "                x_masked = x.clone()\n",
    "                x_masked[mask == 1] = 0\n",
    "                \n",
    "                # Forward pass\n",
    "                column_indices = torch.arange(x.shape[1], device=device)\n",
    "                predictions = model(x_masked, column_indices, mask)\n",
    "                \n",
    "                # Compute metrics\n",
    "                loss = compute_loss(predictions, x, mask)\n",
    "                rmse = compute_rmse(predictions, x, mask)\n",
    "                nrmse = compute_nrmse(predictions, x, mask)\n",
    "                \n",
    "                # Update mechanism-specific metrics\n",
    "                mechanism_metrics[mechanism][\"loss\"] += loss.item()\n",
    "                mechanism_metrics[mechanism][\"rmse\"] += rmse\n",
    "                mechanism_metrics[mechanism][\"nrmse\"] += nrmse\n",
    "                mechanism_metrics[mechanism][\"count\"] += 1\n",
    "                \n",
    "                # Update overall metrics\n",
    "                total_loss += loss.item()\n",
    "                total_rmse += rmse\n",
    "                total_nrmse += nrmse\n",
    "    \n",
    "    # Calculate averages\n",
    "    num_evaluations = len(dataloader) * len(mechanisms)\n",
    "    avg_loss = total_loss / num_evaluations\n",
    "    avg_rmse = total_rmse / num_evaluations\n",
    "    avg_nrmse = total_nrmse / num_evaluations\n",
    "    \n",
    "    # Calculate mechanism-specific averages\n",
    "    for m in mechanisms:\n",
    "        if mechanism_metrics[m][\"count\"] > 0:\n",
    "            mechanism_metrics[m][\"loss\"] /= mechanism_metrics[m][\"count\"]\n",
    "            mechanism_metrics[m][\"rmse\"] /= mechanism_metrics[m][\"count\"]\n",
    "            mechanism_metrics[m][\"nrmse\"] /= mechanism_metrics[m][\"count\"]\n",
    "    \n",
    "    return {\n",
    "        \"loss\": avg_loss,\n",
    "        \"rmse\": avg_rmse,\n",
    "        \"nrmse\": avg_nrmse,\n",
    "        \"mechanisms\": mechanism_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot training history.\n",
    "    \n",
    "    Args:\n",
    "        history (dict): Training history\n",
    "        save_path (str, optional): Path to save the plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot NRMSE\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history[\"val_nrmse\"], label=\"Overall NRMSE\")\n",
    "    plt.plot(history[\"val_mcar_nrmse\"], label=\"MCAR NRMSE\")\n",
    "    plt.plot(history[\"val_mar_nrmse\"], label=\"MAR NRMSE\")\n",
    "    plt.plot(history[\"val_mnar_nrmse\"], label=\"MNAR NRMSE\")\n",
    "    plt.title(\"NRMSE by Mechanism\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"NRMSE\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot learning rate\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history[\"lr\"])\n",
    "    plt.title(\"Learning Rate\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, scaler, config, save_dir=\"models\"):\n",
    "    \"\"\"\n",
    "    Save model and related objects.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model\n",
    "        scaler (StandardScaler): Data scaler\n",
    "        config (dict): Model configuration\n",
    "        save_dir (str): Directory to save model\n",
    "    \"\"\"\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(save_dir, \"tabular_transformer_relpos.pth\")\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"config\": config\n",
    "    }, model_path)\n",
    "    \n",
    "    # Save scaler\n",
    "    scaler_path = os.path.join(save_dir, \"scaler.pkl\")\n",
    "    with open(scaler_path, \"wb\") as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    print(f\"Scaler saved to {scaler_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, val_data, column_indices, config, model_type=\"single\"):\n",
    "    \"\"\"\n",
    "    Train the model (single model or ensemble).\n",
    "    \n",
    "    Args:\n",
    "        train_data (torch.Tensor): Training data\n",
    "        val_data (torch.Tensor): Validation data\n",
    "        column_indices (torch.Tensor): Column indices\n",
    "        config (dict): Configuration dictionary\n",
    "        model_type (str): Type of model to train (\"single\" or \"ensemble\")\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Trained model and training history\n",
    "    \"\"\"\n",
    "    print(\"Starting model training...\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataset = TensorDataset(train_data)\n",
    "    val_dataset = TensorDataset(val_data)\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config[\"batch_size\"], \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config[\"batch_size\"]\n",
    "    )\n",
    "    \n",
    "    # Create model based on type\n",
    "    num_features = train_data.shape[1]\n",
    "    \n",
    "    if model_type == \"ensemble\":\n",
    "        print(\"Creating ensemble model with 3 base models...\")\n",
    "        model = EnsembleModel(\n",
    "            num_features=num_features,\n",
    "            config=config,\n",
    "            num_models=3\n",
    "        ).to(device)\n",
    "    else:\n",
    "        print(\"Creating single transformer model...\")\n",
    "        model = TabularTransformerWithRelPos(\n",
    "            num_features=num_features,\n",
    "            d_model=config[\"d_model\"],\n",
    "            nhead=config[\"num_heads\"],\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            dim_feedforward=config[\"dim_feedforward\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            activation=config[\"activation\"],\n",
    "            max_seq_len=max(2 * num_features, 100)  # Set max_seq_len based on feature count\n",
    "        ).to(device)\n",
    "    \n",
    "    # Set up optimizer and scheduler\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"learning_rate\"],\n",
    "        weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler - use OneCycleLR for better convergence\n",
    "    total_steps = len(train_dataloader) * config[\"num_epochs\"]\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config[\"learning_rate\"],\n",
    "        total_steps=total_steps,\n",
    "        pct_start=0.3,  # Warm-up phase percentage\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0,  # Initial lr = max_lr/div_factor\n",
    "        final_div_factor=10000.0  # Final lr = initial_lr/final_div_factor\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_rmse\": [],\n",
    "        \"val_nrmse\": [],\n",
    "        \"val_mcar_nrmse\": [],\n",
    "        \"val_mar_nrmse\": [],\n",
    "        \"val_mnar_nrmse\": [],\n",
    "        \"lr\": []\n",
    "    }\n",
    "    \n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    mechanisms = [\"MCAR\", \"MAR\", \"MNAR\"]\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{config['num_epochs']}\")\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = train_epoch(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            optimizer,\n",
    "            config[\"missing_fraction\"],\n",
    "            mechanisms,\n",
    "            scheduler,\n",
    "            focus_mnar=False\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_metrics = validate(\n",
    "            model,\n",
    "            val_dataloader,\n",
    "            config[\"missing_fraction\"],\n",
    "            mechanisms\n",
    "        )\n",
    "        \n",
    "        # Update history\n",
    "        history[\"train_loss\"].append(train_metrics[\"loss\"])\n",
    "        history[\"val_loss\"].append(val_metrics[\"loss\"])\n",
    "        history[\"val_rmse\"].append(val_metrics[\"rmse\"])\n",
    "        history[\"val_nrmse\"].append(val_metrics[\"nrmse\"])\n",
    "        history[\"val_mcar_nrmse\"].append(val_metrics[\"mechanisms\"][\"MCAR\"][\"nrmse\"])\n",
    "        history[\"val_mar_nrmse\"].append(val_metrics[\"mechanisms\"][\"MAR\"][\"nrmse\"])\n",
    "        history[\"val_mnar_nrmse\"].append(val_metrics[\"mechanisms\"][\"MNAR\"][\"nrmse\"])\n",
    "        history[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train Loss: {train_metrics['loss']:.4f}\")\n",
    "        print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n",
    "        print(f\"Val NRMSE: {val_metrics['nrmse']:.4f}\")\n",
    "        print(f\"Val MCAR NRMSE: {val_metrics['mechanisms']['MCAR']['nrmse']:.4f}\")\n",
    "        print(f\"Val MAR NRMSE: {val_metrics['mechanisms']['MAR']['nrmse']:.4f}\")\n",
    "        print(f\"Val MNAR NRMSE: {val_metrics['mechanisms']['MNAR']['nrmse']:.4f}\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_metrics[\"loss\"] < best_val_loss:\n",
    "            best_val_loss = val_metrics[\"loss\"]\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f\"New best validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement for {patience_counter} epochs\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= config[\"patience\"]:\n",
    "            print(f\"Early stopping after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_weights is not None:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(data, column_indices, config, n_folds=5, model_type=\"single\"):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation.\n",
    "    \n",
    "    Args:\n",
    "        data (torch.Tensor): Data to split\n",
    "        column_indices (torch.Tensor): Feature column indices\n",
    "        config (dict): Configuration dictionary\n",
    "        n_folds (int): Number of folds\n",
    "        model_type (str): Type of model to train (\"single\" or \"ensemble\")\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with average metrics across folds\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    all_metrics = []\n",
    "    all_models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
    "        print(f\"\\nTraining fold {fold+1}/{n_folds}\")\n",
    "        \n",
    "        # Split data\n",
    "        train_data = data[train_idx]\n",
    "        val_data = data[val_idx]\n",
    "        \n",
    "        # Train model (can be single or ensemble based on model_type)\n",
    "        model, history = train_model(train_data, val_data, column_indices, config, model_type=model_type)\n",
    "        \n",
    "        # Store model\n",
    "        all_models.append(model)\n",
    "        \n",
    "        # Validate\n",
    "        val_dataloader = DataLoader(TensorDataset(val_data), batch_size=config[\"batch_size\"])\n",
    "        metrics = validate(model, val_dataloader, config[\"missing_fraction\"], [\"MCAR\", \"MAR\", \"MNAR\"])\n",
    "        \n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        print(f\"Fold {fold+1} metrics:\")\n",
    "        print(f\"  NRMSE: {metrics['nrmse']:.4f}\")\n",
    "        print(f\"  MCAR NRMSE: {metrics['mechanisms']['MCAR']['nrmse']:.4f}\")\n",
    "        print(f\"  MAR NRMSE: {metrics['mechanisms']['MAR']['nrmse']:.4f}\")\n",
    "        print(f\"  MNAR NRMSE: {metrics['mechanisms']['MNAR']['nrmse']:.4f}\")\n",
    "    \n",
    "    # Average metrics across folds\n",
    "    avg_metrics = {\n",
    "        \"nrmse\": np.mean([m[\"nrmse\"] for m in all_metrics]),\n",
    "        \"mcar_nrmse\": np.mean([m[\"mechanisms\"][\"MCAR\"][\"nrmse\"] for m in all_metrics]),\n",
    "        \"mar_nrmse\": np.mean([m[\"mechanisms\"][\"MAR\"][\"nrmse\"] for m in all_metrics]),\n",
    "        \"mnar_nrmse\": np.mean([m[\"mechanisms\"][\"MNAR\"][\"nrmse\"] for m in all_metrics])\n",
    "    }\n",
    "    \n",
    "    # Standard deviation of metrics\n",
    "    std_metrics = {\n",
    "        \"nrmse_std\": np.std([m[\"nrmse\"] for m in all_metrics]),\n",
    "        \"mcar_nrmse_std\": np.std([m[\"mechanisms\"][\"MCAR\"][\"nrmse\"] for m in all_metrics]),\n",
    "        \"mar_nrmse_std\": np.std([m[\"mechanisms\"][\"MAR\"][\"nrmse\"] for m in all_metrics]),\n",
    "        \"mnar_nrmse_std\": np.std([m[\"mechanisms\"][\"MNAR\"][\"nrmse\"] for m in all_metrics])\n",
    "    }\n",
    "    \n",
    "    # Add standard deviations to results\n",
    "    avg_metrics.update(std_metrics)\n",
    "    \n",
    "    print(\"\\nAverage metrics across folds:\")\n",
    "    print(f\"  NRMSE: {avg_metrics['nrmse']:.4f} ± {avg_metrics['nrmse_std']:.4f}\")\n",
    "    print(f\"  MCAR NRMSE: {avg_metrics['mcar_nrmse']:.4f} ± {avg_metrics['mcar_nrmse_std']:.4f}\")\n",
    "    print(f\"  MAR NRMSE: {avg_metrics['mar_nrmse']:.4f} ± {avg_metrics['mar_nrmse_std']:.4f}\")\n",
    "    print(f\"  MNAR NRMSE: {avg_metrics['mnar_nrmse']:.4f} ± {avg_metrics['mnar_nrmse_std']:.4f}\")\n",
    "    \n",
    "    return avg_metrics, all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnar_specialized_model(train_data, val_data, column_indices, config):\n",
    "    \"\"\"\n",
    "    Train a model specialized for MNAR data.\n",
    "    \n",
    "    Args:\n",
    "        train_data (torch.Tensor): Training data\n",
    "        val_data (torch.Tensor): Validation data\n",
    "        column_indices (torch.Tensor): Column indices\n",
    "        config (dict): Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Trained model and training history\n",
    "    \"\"\"\n",
    "    print(\"Starting specialized MNAR model training...\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataset = TensorDataset(train_data)\n",
    "    val_dataset = TensorDataset(val_data)\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config[\"batch_size\"], \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config[\"batch_size\"]\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    num_features = train_data.shape[1]\n",
    "    model = TabularTransformerWithRelPos(\n",
    "        num_features=num_features,\n",
    "        d_model=config[\"d_model\"],\n",
    "        nhead=config[\"num_heads\"],\n",
    "        num_layers=config[\"num_layers\"],\n",
    "        dim_feedforward=config[\"dim_feedforward\"],\n",
    "        dropout=config[\"dropout\"],\n",
    "        activation=config[\"activation\"],\n",
    "        max_seq_len=max(2 * num_features, 100)\n",
    "    ).to(device)\n",
    "    \n",
    "    # Set up optimizer and scheduler\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"learning_rate\"],\n",
    "        weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    total_steps = len(train_dataloader) * config[\"num_epochs\"]\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config[\"learning_rate\"],\n",
    "        total_steps=total_steps,\n",
    "        pct_start=0.3,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0,\n",
    "        final_div_factor=10000.0\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_mnar_nrmse\": [],\n",
    "        \"lr\": []\n",
    "    }\n",
    "    \n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Only train with MNAR mechanism\n",
    "    mechanisms = [\"MNAR\"]\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{config['num_epochs']}\")\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = train_epoch(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            optimizer,\n",
    "            config[\"missing_fraction\"],\n",
    "            mechanisms,\n",
    "            scheduler,\n",
    "            focus_mnar=True\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_metrics = validate(\n",
    "            model,\n",
    "            val_dataloader,\n",
    "            config[\"missing_fraction\"],\n",
    "            mechanisms\n",
    "        )\n",
    "        \n",
    "        # Update history\n",
    "        history[\"train_loss\"].append(train_metrics[\"loss\"])\n",
    "        history[\"val_loss\"].append(val_metrics[\"loss\"])\n",
    "        history[\"val_mnar_nrmse\"].append(val_metrics[\"mechanisms\"][\"MNAR\"][\"nrmse\"])\n",
    "        history[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train Loss: {train_metrics['loss']:.4f}\")\n",
    "        print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n",
    "        print(f\"Val MNAR NRMSE: {val_metrics['mechanisms']['MNAR']['nrmse']:.4f}\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_metrics[\"loss\"] < best_val_loss:\n",
    "            best_val_loss = val_metrics[\"loss\"]\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f\"New best validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement for {patience_counter} epochs\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= config[\"patience\"]:\n",
    "            print(f\"Early stopping after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_weights is not None:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution code\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    config = {\n",
    "        # Data parameters\n",
    "        \"data_path\": \"./data/physionet_39_features_only.csv\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"val_size\": 0.1,\n",
    "        \n",
    "        # Model parameters\n",
    "        \"d_model\": 384,              # Increased from 256\n",
    "        \"num_heads\": 12,             # Increased from 8\n",
    "        \"num_layers\": 6,             # Increased from 5\n",
    "        \"dim_feedforward\": 1536,     # Increased from 1024\n",
    "        \"dropout\": 0.15,             # Reduced from 0.2 for better generalization\n",
    "        \"activation\": \"gelu\",\n",
    "        \n",
    "        # Training parameters\n",
    "        \"batch_size\": 128,           # Increased from 64\n",
    "        \"learning_rate\": 0.0015,     # Slightly higher for faster initial training\n",
    "        \"weight_decay\": 0.005,       # Reduced from 0.01\n",
    "        \"num_epochs\": 200,           # Doubled from 100\n",
    "        \"patience\": 25,              # Increased from 15\n",
    "        \"missing_fraction\": 0.3,\n",
    "        \n",
    "        \"warmup_steps_pct\": 0.2,     # Shorter warmup phase\n",
    "        \"min_lr_factor\": 5000.0,     # Slower final decay\n",
    "        \n",
    "        # Save parameters\n",
    "        \"save_dir\": \"models\"\n",
    "    }\n",
    "    \n",
    "    # Create directories with timestamp\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    save_dir = os.path.join(config[\"save_dir\"], f\"{current_time}_model-ensemble+5Fold\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Create experiment log file\n",
    "    experiment_log = os.path.join(save_dir, \"experiment_log.txt\")\n",
    "    with open(experiment_log, \"w\") as f:\n",
    "        f.write(f\"Experiment started at: {current_time}\\n\")\n",
    "        f.write(\"Configuration:\\n\")\n",
    "        for key, value in config.items():\n",
    "            f.write(f\"  {key}: {value}\\n\")\n",
    "    \n",
    "    # Load and prepare data\n",
    "    train_data, val_data, test_data, scaler, column_indices = load_and_prepare_data(\n",
    "        config[\"data_path\"],\n",
    "        config[\"test_size\"],\n",
    "        config[\"val_size\"]\n",
    "    )\n",
    "    \n",
    "    # Add flag to control whether to run k-fold validation\n",
    "    RUN_KFOLD = True\n",
    "    \n",
    "    if RUN_KFOLD:\n",
    "        print(\"\\n=== Running K-Fold Cross-Validation ===\")\n",
    "        # Combine train and validation data for k-fold\n",
    "        combined_data = torch.cat([train_data, val_data], dim=0)\n",
    "        \n",
    "        # Set a smaller number of epochs for k-fold to save time\n",
    "        kfold_config = config.copy()\n",
    "        kfold_config[\"num_epochs\"] = 100  # Reduced epochs for k-fold\n",
    "        \n",
    "        # Run k-fold validation with single model\n",
    "        print(\"\\n---- K-Fold with Single Model ----\")\n",
    "        cv_metrics_single, _ = cross_validate_model(\n",
    "            combined_data, \n",
    "            column_indices, \n",
    "            kfold_config, \n",
    "            n_folds=5,\n",
    "            model_type=\"single\"\n",
    "        )\n",
    "        \n",
    "        # Run k-fold validation with ensemble model\n",
    "        print(\"\\n---- K-Fold with Ensemble Model ----\")\n",
    "        cv_metrics_ensemble, _ = cross_validate_model(\n",
    "            combined_data, \n",
    "            column_indices, \n",
    "            kfold_config, \n",
    "            n_folds=3,  # Fewer folds for ensemble to save time\n",
    "            model_type=\"ensemble\"\n",
    "        )\n",
    "        \n",
    "        # Save cross-validation results\n",
    "        cv_results_path = os.path.join(save_dir, \"cv_results.txt\")\n",
    "        with open(cv_results_path, \"w\") as f:\n",
    "            f.write(\"Single Model Cross-Validation Results:\\n\")\n",
    "            f.write(f\"  NRMSE: {cv_metrics_single['nrmse']:.4f} ± {cv_metrics_single['nrmse_std']:.4f}\\n\")\n",
    "            f.write(f\"  MCAR NRMSE: {cv_metrics_single['mcar_nrmse']:.4f} ± {cv_metrics_single['mcar_nrmse_std']:.4f}\\n\")\n",
    "            f.write(f\"  MAR NRMSE: {cv_metrics_single['mar_nrmse']:.4f} ± {cv_metrics_single['mar_nrmse_std']:.4f}\\n\")\n",
    "            f.write(f\"  MNAR NRMSE: {cv_metrics_single['mnar_nrmse']:.4f} ± {cv_metrics_single['mnar_nrmse_std']:.4f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Ensemble Model Cross-Validation Results:\\n\")\n",
    "            f.write(f\"  NRMSE: {cv_metrics_ensemble['nrmse']:.4f} ± {cv_metrics_ensemble['nrmse_std']:.4f}\\n\")\n",
    "            f.write(f\"  MCAR NRMSE: {cv_metrics_ensemble['mcar_nrmse']:.4f} ± {cv_metrics_ensemble['mcar_nrmse_std']:.4f}\\n\")\n",
    "            f.write(f\"  MAR NRMSE: {cv_metrics_ensemble['mar_nrmse']:.4f} ± {cv_metrics_ensemble['mar_nrmse_std']:.4f}\\n\")\n",
    "            f.write(f\"  MNAR NRMSE: {cv_metrics_ensemble['mnar_nrmse']:.4f} ± {cv_metrics_ensemble['mnar_nrmse_std']:.4f}\\n\")\n",
    "    \n",
    "    # Choose model type based on cross-validation results (if performed)\n",
    "    if RUN_KFOLD and cv_metrics_ensemble['nrmse'] < cv_metrics_single['nrmse']:\n",
    "        print(\"\\nEnsemble model performed better in cross-validation. Using ensemble for final model.\")\n",
    "        final_model_type = \"ensemble\"\n",
    "    else:\n",
    "        print(\"\\nUsing single model for final training.\")\n",
    "        final_model_type = \"single\"\n",
    "    \n",
    "    # Train final model on the entire training set\n",
    "    print(\"\\n=== Training Final Model ===\")\n",
    "    model, history = train_model(train_data, val_data, column_indices, config, model_type=final_model_type)\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history, os.path.join(save_dir, \"training_history.png\"))\n",
    "    \n",
    "    # Create specialized MNAR model\n",
    "    TRAIN_SPECIALIZED = True\n",
    "    \n",
    "    if TRAIN_SPECIALIZED:\n",
    "        print(\"\\n=== Training Specialized MNAR Model ===\")\n",
    "        mnar_config = config.copy()\n",
    "        mnar_config[\"learning_rate\"] = 0.001  # Slightly lower learning rate\n",
    "        mnar_config[\"num_epochs\"] = 150  # Fewer epochs\n",
    "        \n",
    "        mnar_model, mnar_history = train_mnar_specialized_model(\n",
    "            train_data, val_data, column_indices, mnar_config\n",
    "        )\n",
    "        \n",
    "        # Plot MNAR model training history\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(mnar_history[\"train_loss\"], label=\"Train Loss\")\n",
    "        plt.plot(mnar_history[\"val_loss\"], label=\"Val Loss\")\n",
    "        plt.plot(mnar_history[\"val_mnar_nrmse\"], label=\"Val MNAR NRMSE\")\n",
    "        plt.title(\"MNAR Specialized Model Training\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(save_dir, \"mnar_model_history.png\"))\n",
    "        \n",
    "        # Evaluate MNAR model on test set\n",
    "        test_dataloader = DataLoader(TensorDataset(test_data), batch_size=config[\"batch_size\"])\n",
    "        mnar_test_metrics = validate(mnar_model, test_dataloader, config[\"missing_fraction\"], [\"MNAR\"])\n",
    "        \n",
    "        print(f\"MNAR Specialized Model - Test MNAR NRMSE: {mnar_test_metrics['mechanisms']['MNAR']['nrmse']:.4f}\")\n",
    "        \n",
    "        # Save MNAR model\n",
    "        mnar_model_path = os.path.join(save_dir, \"mnar_specialized_model.pth\")\n",
    "        torch.save({\n",
    "            \"model_state_dict\": mnar_model.state_dict(),\n",
    "            \"config\": mnar_config\n",
    "        }, mnar_model_path)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\n=== Evaluating on Test Set ===\")\n",
    "    test_dataloader = DataLoader(TensorDataset(test_data), batch_size=config[\"batch_size\"])\n",
    "    test_metrics = validate(model, test_dataloader, config[\"missing_fraction\"], [\"MCAR\", \"MAR\", \"MNAR\"])\n",
    "    \n",
    "    print(f\"Test metrics:\")\n",
    "    print(f\"  Overall NRMSE: {test_metrics['nrmse']:.4f}\")\n",
    "    print(f\"  MCAR NRMSE: {test_metrics['mechanisms']['MCAR']['nrmse']:.4f}\")\n",
    "    print(f\"  MAR NRMSE: {test_metrics['mechanisms']['MAR']['nrmse']:.4f}\")\n",
    "    print(f\"  MNAR NRMSE: {test_metrics['mechanisms']['MNAR']['nrmse']:.4f}\")\n",
    "    \n",
    "    # Create hybrid predictor for MNAR if the specialized model exists\n",
    "    if TRAIN_SPECIALIZED:\n",
    "        print(\"\\n=== Creating Hybrid Predictor ===\")\n",
    "        # Function to combine predictions for hybrid approach\n",
    "        def predict_hybrid(data, mask, general_model, mnar_model, column_indices):\n",
    "            general_model.eval()\n",
    "            mnar_model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Get predictions from both models\n",
    "                general_preds = general_model(data, column_indices, mask)\n",
    "                mnar_preds = mnar_model(data, column_indices, mask)\n",
    "                \n",
    "                # Create a new mask that's zero for MCAR/MAR and one for MNAR\n",
    "                # For simplicity, we're randomly assigning mechanisms per sample\n",
    "                mnar_indicator = torch.zeros_like(mask)\n",
    "                for i in range(mask.size(0)):\n",
    "                    # Assign this sample to MNAR with 1/3 probability\n",
    "                    if random.random() < 0.333:\n",
    "                        mnar_indicator[i] = 1\n",
    "                \n",
    "                # Combine predictions: use MNAR model for MNAR patterns and general model for others\n",
    "                combined_preds = (1 - mnar_indicator) * general_preds + mnar_indicator * mnar_preds\n",
    "                \n",
    "                return combined_preds\n",
    "        \n",
    "        # Test the hybrid approach\n",
    "        print(\"Testing hybrid approach on test set...\")\n",
    "        \n",
    "        # First, create a mask for the whole test set\n",
    "        test_hybrid_metrics = {\"mcar\": 0, \"mar\": 0, \"mnar\": 0, \"overall\": 0}\n",
    "        test_count = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                x = batch[0].to(device)\n",
    "                \n",
    "                for mechanism in [\"MCAR\", \"MAR\", \"MNAR\"]:\n",
    "                    # Create a mask based on the mechanism\n",
    "                    mask = create_missing_mask(x, config[\"missing_fraction\"], mechanism)\n",
    "                    \n",
    "                    # Create input with missing values\n",
    "                    x_masked = x.clone()\n",
    "                    x_masked[mask == 1] = 0\n",
    "                    \n",
    "                    # Get column indices\n",
    "                    col_indices = torch.arange(x.shape[1], device=device)\n",
    "                    \n",
    "                    # Predict using the hybrid approach\n",
    "                    if mechanism == \"MNAR\":\n",
    "                        # Use MNAR specialized model\n",
    "                        predictions = mnar_model(x_masked, col_indices, mask)\n",
    "                    else:\n",
    "                        # Use general model\n",
    "                        predictions = model(x_masked, col_indices, mask)\n",
    "                    \n",
    "                    # Calculate NRMSE\n",
    "                    nrmse = compute_nrmse(predictions, x, mask)\n",
    "                    test_hybrid_metrics[mechanism.lower()] += nrmse\n",
    "                    test_hybrid_metrics[\"overall\"] += nrmse\n",
    "                    test_count += 1\n",
    "        \n",
    "        # Calculate average\n",
    "        for key in test_hybrid_metrics:\n",
    "            test_hybrid_metrics[key] /= (test_count / 3)  # Divide by number of mechanisms\n",
    "        \n",
    "        print(f\"Hybrid approach test results:\")\n",
    "        print(f\"  Overall NRMSE: {test_hybrid_metrics['overall']:.4f}\")\n",
    "        print(f\"  MCAR NRMSE: {test_hybrid_metrics['mcar']:.4f}\")\n",
    "        print(f\"  MAR NRMSE: {test_hybrid_metrics['mar']:.4f}\")\n",
    "        print(f\"  MNAR NRMSE: {test_hybrid_metrics['mnar']:.4f}\")\n",
    "    \n",
    "    # Save test results\n",
    "    test_results_path = os.path.join(save_dir, \"test_results.txt\")\n",
    "    with open(test_results_path, \"w\") as f:\n",
    "        f.write(\"Test Results:\\n\")\n",
    "        f.write(f\"  Overall NRMSE: {test_metrics['nrmse']:.4f}\\n\")\n",
    "        f.write(f\"  MCAR NRMSE: {test_metrics['mechanisms']['MCAR']['nrmse']:.4f}\\n\")\n",
    "        f.write(f\"  MAR NRMSE: {test_metrics['mechanisms']['MAR']['nrmse']:.4f}\\n\")\n",
    "        f.write(f\"  MNAR NRMSE: {test_metrics['mechanisms']['MNAR']['nrmse']:.4f}\\n\")\n",
    "        \n",
    "        if TRAIN_SPECIALIZED:\n",
    "            f.write(\"\\nHybrid Model Results:\\n\")\n",
    "            f.write(f\"  Overall NRMSE: {test_hybrid_metrics['overall']:.4f}\\n\")\n",
    "            f.write(f\"  MCAR NRMSE: {test_hybrid_metrics['mcar']:.4f}\\n\")\n",
    "            f.write(f\"  MAR NRMSE: {test_hybrid_metrics['mar']:.4f}\\n\")\n",
    "            f.write(f\"  MNAR NRMSE: {test_hybrid_metrics['mnar']:.4f}\\n\")\n",
    "    \n",
    "    # Save models\n",
    "    print(f\"\\n=== Saving Models ===\")\n",
    "    \n",
    "    # Save final model\n",
    "    model_save_path = os.path.join(save_dir, \"final_model.pth\")\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"config\": config,\n",
    "        \"model_type\": final_model_type\n",
    "    }, model_save_path)\n",
    "    \n",
    "    # Save scaler\n",
    "    scaler_path = os.path.join(save_dir, \"scaler.pkl\")\n",
    "    with open(scaler_path, \"wb\") as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    # Update experiment log\n",
    "    with open(experiment_log, \"a\") as f:\n",
    "        f.write(\"\\nFinal Test Results:\\n\")\n",
    "        f.write(f\"  Overall NRMSE: {test_metrics['nrmse']:.4f}\\n\")\n",
    "        f.write(f\"  MCAR NRMSE: {test_metrics['mechanisms']['MCAR']['nrmse']:.4f}\\n\")\n",
    "        f.write(f\"  MAR NRMSE: {test_metrics['mechanisms']['MAR']['nrmse']:.4f}\\n\")\n",
    "        f.write(f\"  MNAR NRMSE: {test_metrics['mechanisms']['MNAR']['nrmse']:.4f}\\n\")\n",
    "        \n",
    "        if TRAIN_SPECIALIZED:\n",
    "            f.write(\"\\nHybrid Model Results:\\n\")\n",
    "            f.write(f\"  Overall NRMSE: {test_hybrid_metrics['overall']:.4f}\\n\")\n",
    "            f.write(f\"  MCAR NRMSE: {test_hybrid_metrics['mcar']:.4f}\\n\")\n",
    "            f.write(f\"  MAR NRMSE: {test_hybrid_metrics['mar']:.4f}\\n\")\n",
    "            f.write(f\"  MNAR NRMSE: {test_hybrid_metrics['mnar']:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nExperiment completed at: {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")\n",
    "\n",
    "    print(f\"Training complete! All models and results saved in: {save_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_imputation_performance(model, test_data, column_indices, missing_percentages=[0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                                    mechanisms=[\"MCAR\", \"MAR\", \"MNAR\"]):\n",
    "    \"\"\"\n",
    "    Evaluate the model's imputation performance across different missing percentages and mechanisms.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model\n",
    "        test_data (torch.Tensor): Test data tensor\n",
    "        column_indices (torch.Tensor): Column indices\n",
    "        missing_percentages (list): List of missing data percentages to evaluate\n",
    "        mechanisms (list): List of missing data mechanisms to evaluate\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with NRMSE results for each mechanism and percentage\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for mechanism in mechanisms:\n",
    "            mechanism_results = []\n",
    "            \n",
    "            for missing_pct in missing_percentages:\n",
    "                batch_size = 128\n",
    "                total_nrmse = 0\n",
    "                num_batches = 0\n",
    "                \n",
    "                # Create DataLoader for test data\n",
    "                test_dataloader = DataLoader(TensorDataset(test_data), batch_size=batch_size)\n",
    "                \n",
    "                for batch in tqdm(test_dataloader, desc=f\"Evaluating {mechanism} at {missing_pct*100}%\"):\n",
    "                    x = batch[0].to(device)\n",
    "                    \n",
    "                    # Create a mask for missing values\n",
    "                    mask = create_missing_mask(x, missing_pct, mechanism)\n",
    "                    \n",
    "                    # Create input with missing values set to 0\n",
    "                    x_masked = x.clone()\n",
    "                    x_masked[mask == 1] = 0\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    predictions = model(x_masked, column_indices, mask)\n",
    "                    \n",
    "                    # Compute NRMSE\n",
    "                    nrmse = compute_nrmse(predictions, x, mask)\n",
    "                    total_nrmse += nrmse\n",
    "                    num_batches += 1\n",
    "                \n",
    "                avg_nrmse = total_nrmse / num_batches\n",
    "                mechanism_results.append(avg_nrmse)\n",
    "                print(f\"{mechanism} at {missing_pct*100}% missing: NRMSE = {avg_nrmse:.4f}\")\n",
    "            \n",
    "            results[mechanism] = mechanism_results\n",
    "    \n",
    "    # Create a DataFrame for visualization\n",
    "    results_df = pd.DataFrame(results, index=[f\"{int(pct*100)}%\" for pct in missing_percentages])\n",
    "    results_df.index.name = \"Missing Percentage\"\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_imputation_performance(results_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Create visualizations for imputation performance.\n",
    "    \n",
    "    Args:\n",
    "        results_df (pd.DataFrame): DataFrame with NRMSE results\n",
    "        save_path (str, optional): Path to save the figures\n",
    "    \"\"\"\n",
    "    # 1. Create a heatmap visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create a heatmap with custom colormap (lower values = better = greener)\n",
    "    sns.heatmap(results_df, annot=True, cmap=\"RdYlGn_r\", fmt=\".4f\", \n",
    "                linewidths=.5, cbar_kws={'label': 'NRMSE (lower is better)'})\n",
    "    \n",
    "    plt.title(\"Imputation Performance (NRMSE) by Missing Mechanism and Percentage\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        heatmap_path = save_path.replace(\".png\", \"_heatmap.png\")\n",
    "        plt.savefig(heatmap_path)\n",
    "        print(f\"Heatmap saved to {heatmap_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Create a line plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Convert index to numeric for plotting\n",
    "    results_df_plot = results_df.copy()\n",
    "    results_df_plot.index = [int(idx.replace(\"%\", \"\")) for idx in results_df_plot.index]\n",
    "    \n",
    "    # Plot lines for each mechanism\n",
    "    for column in results_df_plot.columns:\n",
    "        plt.plot(results_df_plot.index, results_df_plot[column], marker='o', linewidth=2, label=column)\n",
    "    \n",
    "    plt.xlabel(\"Missing Percentage (%)\")\n",
    "    plt.ylabel(\"NRMSE (lower is better)\")\n",
    "    plt.title(\"Imputation Performance Across Missing Percentages\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.xticks(results_df_plot.index)\n",
    "    \n",
    "    if save_path:\n",
    "        line_path = save_path.replace(\".png\", \"_lineplot.png\")\n",
    "        plt.savefig(line_path)\n",
    "        print(f\"Line plot saved to {line_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Create a bar chart comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot grouped bars\n",
    "    bar_width = 0.25\n",
    "    r = np.arange(len(results_df_plot.index))\n",
    "    \n",
    "    # Plot bars for each mechanism\n",
    "    for i, column in enumerate(results_df_plot.columns):\n",
    "        plt.bar(r + i*bar_width, results_df_plot[column], width=bar_width, label=column)\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.xlabel(\"Missing Percentage (%)\")\n",
    "    plt.ylabel(\"NRMSE (lower is better)\")\n",
    "    plt.title(\"Imputation Performance by Missing Mechanism and Percentage\")\n",
    "    plt.xticks(r + bar_width, results_df_plot.index)\n",
    "    plt.legend()\n",
    "    \n",
    "    if save_path:\n",
    "        bar_path = save_path.replace(\".png\", \"_barchart.png\")\n",
    "        plt.savefig(bar_path)\n",
    "        print(f\"Bar chart saved to {bar_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Create a table visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    \n",
    "    # Create a table with colored cells based on values\n",
    "    # First, normalize the data for coloring\n",
    "    norm_data = results_df.copy()\n",
    "    for col in norm_data.columns:\n",
    "        max_val = norm_data[col].max()\n",
    "        min_val = norm_data[col].min()\n",
    "        if max_val > min_val:\n",
    "            norm_data[col] = (norm_data[col] - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            norm_data[col] = 0\n",
    "    \n",
    "    # Create a table with cell colors\n",
    "    cell_colors = plt.cm.RdYlGn_r(norm_data.values)\n",
    "    table = ax.table(cellText=results_df.values.round(4), \n",
    "                    rowLabels=results_df.index,\n",
    "                    colLabels=results_df.columns,\n",
    "                    cellColours=cell_colors,\n",
    "                    loc='center')\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.5)\n",
    "    \n",
    "    plt.title(\"NRMSE Values by Missing Mechanism and Percentage\", y=0.8)\n",
    "    \n",
    "    if save_path:\n",
    "        table_path = save_path.replace(\".png\", \"_table.png\")\n",
    "        plt.savefig(table_path, bbox_inches='tight')\n",
    "        print(f\"Table visualization saved to {table_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create a section for imputation performance evaluation\n",
    "    print(\"\\n=== Evaluating Imputation Performance Across Missing Percentages ===\")\n",
    "    \n",
    "    # Define the missing percentages to evaluate\n",
    "    missing_percentages = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    mechanisms = [\"MCAR\", \"MAR\", \"MNAR\"]\n",
    "    \n",
    "    # Create a directory for imputation performance visualizations\n",
    "    imputation_dir = os.path.join(save_dir, \"imputation_performance\")\n",
    "    os.makedirs(imputation_dir, exist_ok=True)\n",
    "    \n",
    "    # Evaluate imputation performance\n",
    "    results_df = evaluate_imputation_performance(\n",
    "        model,                    # Use the final trained model\n",
    "        test_data,                # Test data\n",
    "        column_indices,           # Column indices\n",
    "        missing_percentages,      # Missing percentages\n",
    "        mechanisms                # Missing mechanisms\n",
    "    )\n",
    "    \n",
    "    # Save the raw results to CSV\n",
    "    results_csv_path = os.path.join(imputation_dir, \"imputation_results.csv\")\n",
    "    results_df.to_csv(results_csv_path)\n",
    "    print(f\"Raw imputation results saved to {results_csv_path}\")\n",
    "    \n",
    "    # Create and save visualizations\n",
    "    visualize_imputation_performance(\n",
    "        results_df,\n",
    "        save_path=os.path.join(imputation_dir, \"imputation_performance.png\")\n",
    "    )\n",
    "    \n",
    "    # If specialized MNAR model exists, evaluate it too\n",
    "    if TRAIN_SPECIALIZED:\n",
    "        print(\"\\n=== Evaluating MNAR Specialized Model Imputation Performance ===\")\n",
    "        \n",
    "        # Only evaluate the MNAR mechanism for the specialized model\n",
    "        mnar_results_df = evaluate_imputation_performance(\n",
    "            mnar_model,               # The specialized MNAR model\n",
    "            test_data,                # Test data\n",
    "            column_indices,           # Column indices\n",
    "            missing_percentages,      # Missing percentages\n",
    "            [\"MNAR\"]                  # Only MNAR mechanism\n",
    "        )\n",
    "        \n",
    "        # Save the raw results to CSV\n",
    "        mnar_results_csv_path = os.path.join(imputation_dir, \"mnar_specialized_results.csv\")\n",
    "        mnar_results_df.to_csv(mnar_results_csv_path)\n",
    "        print(f\"Raw MNAR specialized results saved to {mnar_results_csv_path}\")\n",
    "        \n",
    "        # Compare general vs specialized model for MNAR\n",
    "        comparison_df = pd.DataFrame({\n",
    "            \"General Model\": results_df[\"MNAR\"],\n",
    "            \"MNAR Specialized\": mnar_results_df[\"MNAR\"]\n",
    "        })\n",
    "        \n",
    "        # Create comparison visualizations\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        comparison_df.plot(kind='bar', figsize=(12, 6))\n",
    "        plt.title(\"Comparison: General vs MNAR Specialized Model\")\n",
    "        plt.xlabel(\"Missing Percentage\")\n",
    "        plt.ylabel(\"NRMSE (lower is better)\")\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(imputation_dir, \"mnar_model_comparison.png\"))\n",
    "        plt.show()\n",
    "        \n",
    "    print(\"\\nImputation performance evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fresh Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_impute_datasets(original_data_path, save_dir, model, mnar_model=None, \n",
    "                               scaler=None, missing_percentages=[0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                               mechanisms=[\"MCAR\", \"MAR\", \"MNAR\"]):\n",
    "    \"\"\"\n",
    "    Create datasets with missing values from the original data,\n",
    "    impute them using the trained model, and save both versions.\n",
    "    \n",
    "    Args:\n",
    "        original_data_path (str): Path to the original CSV file\n",
    "        save_dir (str): Directory to save the datasets\n",
    "        model (nn.Module): Trained imputation model\n",
    "        mnar_model (nn.Module, optional): Specialized MNAR model\n",
    "        scaler (StandardScaler): Fitted scaler for the data\n",
    "        missing_percentages (list): List of missing data percentages\n",
    "        mechanisms (list): List of missing data mechanisms\n",
    "    \"\"\"\n",
    "    print(f\"Loading original dataset from {original_data_path}...\")\n",
    "    \n",
    "    # Load original dataset\n",
    "    df_original = pd.read_csv(original_data_path, index_col=None)\n",
    "    \n",
    "    # Create directory for datasets if it doesn't exist\n",
    "    datasets_dir = os.path.join(save_dir, \"datasets\")\n",
    "    os.makedirs(datasets_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the original dataset (for reference)\n",
    "    original_save_path = os.path.join(datasets_dir, \"original_dataset.csv\")\n",
    "    df_original.to_csv(original_save_path)\n",
    "    print(f\"Original dataset saved to {original_save_path}\")\n",
    "    \n",
    "    # Convert to numpy for processing\n",
    "    data_np = df_original.to_numpy()\n",
    "    \n",
    "    # Scale the data if scaler is provided\n",
    "    if scaler is not None:\n",
    "        data_np_scaled = scaler.transform(data_np)\n",
    "    else:\n",
    "        print(\"Warning: No scaler provided. Using raw data without scaling.\")\n",
    "        data_np_scaled = data_np\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    data_tensor = torch.tensor(data_np_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Create column indices for model\n",
    "    column_indices = torch.arange(data_tensor.shape[1]).to(device)\n",
    "    \n",
    "    # Dictionary to store imputation metrics\n",
    "    imputation_metrics = {\n",
    "        mechanism: {str(int(pct*100)): {} for pct in missing_percentages}\n",
    "        for mechanism in mechanisms\n",
    "    }\n",
    "    \n",
    "    model.eval()\n",
    "    if mnar_model is not None:\n",
    "        mnar_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for mechanism in mechanisms:\n",
    "            for missing_pct in missing_percentages:\n",
    "                print(f\"\\nCreating dataset with {mechanism} missing at {missing_pct*100}%...\")\n",
    "                \n",
    "                # Create a mask for missing values\n",
    "                mask = create_missing_mask(data_tensor, missing_pct, mechanism)\n",
    "                \n",
    "                # Create input with missing values set to 0 (for the model)\n",
    "                data_masked = data_tensor.clone()\n",
    "                data_masked[mask == 1] = 0\n",
    "                \n",
    "                # Apply the model for imputation\n",
    "                if mechanism == \"MNAR\" and mnar_model is not None:\n",
    "                    print(f\"Using specialized MNAR model for imputation...\")\n",
    "                    predictions = mnar_model(data_masked, column_indices, mask)\n",
    "                else:\n",
    "                    predictions = model(data_masked, column_indices, mask)\n",
    "                \n",
    "                # Compute metrics for logging\n",
    "                rmse = compute_rmse(predictions, data_tensor, mask)\n",
    "                nrmse = compute_nrmse(predictions, data_tensor, mask)\n",
    "                \n",
    "                imputation_metrics[mechanism][str(int(missing_pct*100))][\"rmse\"] = rmse\n",
    "                imputation_metrics[mechanism][str(int(missing_pct*100))][\"nrmse\"] = nrmse\n",
    "                \n",
    "                print(f\"Imputation RMSE: {rmse:.4f}, NRMSE: {nrmse:.4f}\")\n",
    "                \n",
    "                # Create masked dataset by introducing NaN values\n",
    "                df_missing = df_original.copy()\n",
    "                mask_np = mask.cpu().numpy().astype(bool)\n",
    "                \n",
    "                # Convert tensor-indexed mask to DataFrame-indexed mask\n",
    "                for i, row in enumerate(mask_np):\n",
    "                    for j, is_missing in enumerate(row):\n",
    "                        if is_missing:\n",
    "                            df_missing.iloc[i, j] = np.nan\n",
    "                \n",
    "                # Create imputed dataset\n",
    "                # First convert predictions back to original scale\n",
    "                imputed_np = predictions.cpu().numpy()\n",
    "                if scaler is not None:\n",
    "                    imputed_np = scaler.inverse_transform(imputed_np)\n",
    "                \n",
    "                # Create a copy of the original with missing values\n",
    "                df_imputed = df_original.copy()\n",
    "                \n",
    "                # Replace only the masked values with their predictions\n",
    "                for i, row in enumerate(mask_np):\n",
    "                    for j, is_missing in enumerate(row):\n",
    "                        if is_missing:\n",
    "                            df_imputed.iloc[i, j] = imputed_np[i, j]\n",
    "                \n",
    "                # Save both datasets\n",
    "                missing_filename = f\"{mechanism}_{int(missing_pct*100)}pct_missing.csv\"\n",
    "                imputed_filename = f\"{mechanism}_{int(missing_pct*100)}pct_imputed.csv\"\n",
    "                \n",
    "                missing_path = os.path.join(datasets_dir, missing_filename)\n",
    "                imputed_path = os.path.join(datasets_dir, imputed_filename)\n",
    "                \n",
    "                df_missing.to_csv(missing_path)\n",
    "                df_imputed.to_csv(imputed_path)\n",
    "                \n",
    "                print(f\"Dataset with missing values saved to {missing_path}\")\n",
    "                print(f\"Imputed dataset saved to {imputed_path}\")\n",
    "    \n",
    "    # Save imputation metrics\n",
    "    metrics_path = os.path.join(datasets_dir, \"imputation_metrics.json\")\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(imputation_metrics, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nImputation metrics saved to {metrics_path}\")\n",
    "    \n",
    "    # Create a summary table of NRMSE values and save as CSV\n",
    "    summary_data = {\n",
    "        f\"{mech}_{pct}%\": imputation_metrics[mech][str(int(float(pct)))][\"nrmse\"] \n",
    "        for mech in mechanisms\n",
    "        for pct in [10, 20, 30, 40, 50]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame([summary_data])\n",
    "    summary_path = os.path.join(datasets_dir, \"imputation_summary.csv\")\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    \n",
    "    print(f\"Imputation summary saved to {summary_path}\")\n",
    "    \n",
    "    return imputation_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run the dataset creation and imputation (to be added at the end of the notebook)\n",
    "if __name__ == \"__main__\":\n",
    "    # Import json if not already imported\n",
    "    import json\n",
    "    \n",
    "    print(\"\\n=== Creating and Imputing Datasets with Missing Values ===\")\n",
    "    \n",
    "    # Define the missing percentages to use\n",
    "    missing_percentages = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    mechanisms = [\"MCAR\", \"MAR\", \"MNAR\"]\n",
    "    \n",
    "    # Create directory for dataset experiment\n",
    "    dataset_dir = os.path.join(save_dir, \"dataset_experiment\")\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    \n",
    "    # Run dataset creation and imputation\n",
    "    imputation_metrics = create_and_impute_datasets(\n",
    "        original_data_path=config[\"data_path\"],\n",
    "        save_dir=dataset_dir,\n",
    "        model=model,  # Main model\n",
    "        mnar_model=mnar_model if TRAIN_SPECIALIZED else None,  # Specialized MNAR model if available\n",
    "        scaler=scaler,  # Data scaler\n",
    "        missing_percentages=missing_percentages,\n",
    "        mechanisms=mechanisms\n",
    "    )\n",
    "    \n",
    "    # Create visualization of imputation results across datasets\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Set up colors and markers for each mechanism\n",
    "    colors = {'MCAR': 'blue', 'MAR': 'green', 'MNAR': 'red'}\n",
    "    markers = {'MCAR': 'o', 'MAR': 's', 'MNAR': '^'}\n",
    "    \n",
    "    # Plot NRMSE for each mechanism and percentage\n",
    "    for mechanism in mechanisms:\n",
    "        x_values = [int(pct) for pct in sorted([p for p in imputation_metrics[mechanism].keys()])]\n",
    "        y_values = [imputation_metrics[mechanism][str(x)][\"nrmse\"] for x in x_values]\n",
    "        \n",
    "        plt.plot(x_values, y_values, \n",
    "                 label=f\"{mechanism}\", \n",
    "                 color=colors[mechanism], \n",
    "                 marker=markers[mechanism],\n",
    "                 linewidth=2,\n",
    "                 markersize=8)\n",
    "    \n",
    "    plt.xlabel(\"Missing Data Percentage (%)\")\n",
    "    plt.ylabel(\"NRMSE (lower is better)\")\n",
    "    plt.title(\"Imputation Performance Across Dataset Variations\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(title=\"Mechanism\")\n",
    "    plt.xticks(x_values)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(dataset_dir, \"dataset_imputation_summary.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    print(f\"Summary plot saved to {plot_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDataset creation and imputation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_original_dataset(trained_model, scaler, save_path=\"imputed_original.csv\"):\n",
    "    \"\"\"\n",
    "    Load the original CSV dataset, impute missing values using the pre-trained transformer model,\n",
    "    and save the imputed dataset.\n",
    "    \n",
    "    Args:\n",
    "        trained_model: The pre-trained imputation model\n",
    "        scaler: The fitted scaler used during model training\n",
    "        save_path: Path to save the imputed dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Imputing Original Dataset ===\")\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    trained_model.eval()\n",
    "    \n",
    "    # File path\n",
    "    original_file_path = \"./data/physionet_39_features_only.csv\"\n",
    "    \n",
    "    # Load the original dataset\n",
    "    print(f\"Loading original dataset from {original_file_path}...\")\n",
    "    df_original = pd.read_csv(original_file_path, index_col=None)\n",
    "    print(f\"Original dataset shape: {df_original.shape}\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_count = df_original.isna().sum().sum()\n",
    "    missing_percentage = (missing_count / (df_original.shape[0] * df_original.shape[1])) * 100\n",
    "    print(f\"Dataset contains {missing_count} missing values ({missing_percentage:.2f}% of all values)\")\n",
    "    \n",
    "    # Create a copy of the original dataset for imputation\n",
    "    df_imputed = df_original.copy()\n",
    "    \n",
    "    # Extract numerical columns for imputation\n",
    "    numerical_cols = df_original.select_dtypes(include=['number']).columns\n",
    "    print(f\"Found {len(numerical_cols)} numerical columns\")\n",
    "    \n",
    "    # Create mask for missing values (True where values are missing)\n",
    "    missing_mask = df_original[numerical_cols].isna()\n",
    "    \n",
    "    # Fill missing values with 0 for initial processing\n",
    "    df_filled = df_original[numerical_cols].fillna(0)\n",
    "    \n",
    "    # Scale the data using the provided scaler\n",
    "    data_scaled = scaler.transform(df_filled)\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    data_tensor = torch.tensor(data_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Create column indices tensor\n",
    "    column_indices = torch.arange(data_tensor.shape[1]).to(device)\n",
    "    \n",
    "    # Create mask tensor (1 where values are missing, 0 otherwise)\n",
    "    mask_tensor = torch.tensor(missing_mask.values, dtype=torch.int).to(device)\n",
    "    \n",
    "    print(\"Performing imputation with trained model...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get predictions from the model\n",
    "        imputed_tensor = trained_model(data_tensor, column_indices, mask_tensor)\n",
    "        \n",
    "        # Convert to numpy for processing\n",
    "        imputed_np = imputed_tensor.cpu().numpy()\n",
    "        \n",
    "        # Inverse transform to original scale\n",
    "        imputed_np = scaler.inverse_transform(imputed_np)\n",
    "        \n",
    "        # Create a DataFrame from the imputed values\n",
    "        imputed_df = pd.DataFrame(imputed_np, columns=numerical_cols, index=df_original.index)\n",
    "        \n",
    "        # Replace missing values in the original dataframe with imputed values\n",
    "        for col in numerical_cols:\n",
    "            if col in df_imputed.columns:\n",
    "                missing_idx = df_imputed[col].isna()\n",
    "                df_imputed.loc[missing_idx, col] = imputed_df.loc[missing_idx, col]\n",
    "    \n",
    "    # Save the imputed dataset\n",
    "    print(f\"Saving imputed dataset to {save_path}...\")\n",
    "    df_imputed.to_csv(save_path)\n",
    "    \n",
    "    # Verification\n",
    "    missing_after = df_imputed[numerical_cols].isna().sum().sum()\n",
    "    print(f\"Missing values in numerical columns after imputation: {missing_after}\")\n",
    "    \n",
    "    total_missing_after = df_imputed.isna().sum().sum()\n",
    "    if total_missing_after > 0:\n",
    "        print(f\"Total missing values after imputation: {total_missing_after}\")\n",
    "        print(\"Note: Non-numerical columns may still contain missing values\")\n",
    "    else:\n",
    "        print(\"All missing values have been successfully imputed\")\n",
    "    \n",
    "    print(\"Imputation complete!\")\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the imputation process\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n=== Running Imputation on Original Dataset ===\")\n",
    "    \n",
    "    # Use the already trained model\n",
    "    # Assuming 'model' and 'scaler' are the trained model and scaler from earlier in the notebook\n",
    "    imputed_data = impute_original_dataset(model, scaler, \"imputed_original.csv\")\n",
    "    \n",
    "    # Display sample of the imputed data\n",
    "    print(\"\\nSample of imputed data:\")\n",
    "    print(imputed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
